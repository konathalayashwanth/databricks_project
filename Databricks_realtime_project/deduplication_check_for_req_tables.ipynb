{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5bf25d09-ec33-4c88-976e-6eb95b7e48da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "\n",
    "##accounts dupication check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e53de8b-d38d-4d7b-a861-1164ff0d0c4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "####unique customers count\n",
    "\n",
    "silvers_account_count = spark.sql(\"select  AccountID from retail_chain_catalog.silver_schema.silver_accounts_cleaned\").count()\n",
    "\n",
    "####unique customer customer count with de_duplication\n",
    "\n",
    "dedupe_accounts= spark.sql(\"\"\"\n",
    "          select * from (\n",
    "          select *,\n",
    "                 row_number() over(partition by AccountID order by _updated_at asc) as rn\n",
    "            from retail_chain_catalog.silver_schema.silver_accounts_cleaned\n",
    "            ) as k\n",
    "            where rn = 1\"\"\").count()\n",
    "\n",
    "####condition\n",
    "\n",
    "duplicate_accounts = silvers_account_count != dedupe_accounts\n",
    "print(duplicate_accounts)\n",
    "\n",
    "\n",
    "dbutils.jobs.taskValues.set(key = \"duplicates_acc\",value = duplicate_accounts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ccec6da1-cbad-4888-a857-b5e037a1d48a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "##transactions duplication check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "609f4fe7-8a72-493a-a5e3-a1188ad8dd97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transactions_count = spark.sql(\"SELECT TransactionID FROM retail_chain_catalog.silver_schema.silver_transactions_cleaned\").count()\n",
    "\n",
    "\n",
    "\n",
    "unique_transaction_count = spark.sql(\"\"\"\n",
    "                                     select * from\n",
    "                                     (\n",
    "                                     select *,\n",
    "                                        row_number() over(partition by TransactionID order by _updated_at asc) as rn\n",
    "                                        from  retail_chain_catalog.silver_schema.silver_transactions_cleaned\n",
    "                                        ) as k\n",
    "                                        where rn = 1\"\"\").count()\n",
    "\n",
    "duplicate_transactions = transactions_count != unique_transaction_count\n",
    "print(duplicate_transactions)\n",
    "\n",
    "dbutils.jobs.taskValues.set(key = \"duplicates_trans\",value = duplicate_transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "524e3020-66fe-4091-8f8b-0f6533294675",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "##loans duplication check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6198b16-368d-4e74-9ff7-3f6b4e14d595",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loans_count = spark.sql(\"SELECT LoanID FROM retail_chain_catalog.silver_schema.silver_loans_cleaned\").count()\n",
    "\n",
    "\n",
    "\n",
    "unique_loans_count = spark.sql(\"\"\"\n",
    "                                     select * from\n",
    "                                     (\n",
    "                                     select *,\n",
    "                                        row_number() over(partition by LoanID order by _updated_at asc) as rn\n",
    "                                        from  retail_chain_catalog.silver_schema.silver_loans_cleaned\n",
    "                                        ) as k\n",
    "                                        where rn = 1\"\"\").count()\n",
    "\n",
    "duplicate_loans = loans_count != unique_loans_count\n",
    "print(duplicate_loans)\n",
    "\n",
    "dbutils.jobs.taskValues.set(key = \"duplicates_loan\",value = duplicate_loans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4906ec9-4722-4d5b-a831-cd0aeee809cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "##branches duplication check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96c16dd4-fa36-467b-8bd6-df9e69446d64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "branches_count = spark.sql(\"SELECT BranchID FROM retail_chain_catalog.silver_schema.silver_branches_cleaned\").count()\n",
    "\n",
    "\n",
    "\n",
    "unique_branches_count = spark.sql(\"\"\"\n",
    "                                     select * from\n",
    "                                     (\n",
    "                                     select *,\n",
    "                                        row_number() over(partition by BranchID order by _updated_at asc) as rn\n",
    "                                        from  retail_chain_catalog.silver_schema.silver_branches_cleaned\n",
    "                                        ) as k\n",
    "                                        where rn = 1\"\"\").count()\n",
    "\n",
    "duplicate_branches = branches_count != unique_branches_count\n",
    "print(duplicate_branches)\n",
    "\n",
    "dbutils.jobs.taskValues.set(key = \"duplicates_bran\",value = duplicate_branches)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "deduplication_check_for_req_tables",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
